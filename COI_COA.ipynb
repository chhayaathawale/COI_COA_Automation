{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177329ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PROCESSING] fis based → Sample Folder: Sample 1\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_fis\\Temp_Exhibit_ES_Kuhne&Nagel_29.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] fis based → Sample Folder: Sample 2\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_fis\\Temp_Exhibit_DE_Cargill_30.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] fis based → Sample Folder: Sample 3\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_fis\\Temp_Exhibit_FR_Renault_30.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] fis based → Sample Folder: Sample 4\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_fis\\Temp_exhibit_BE_LIDL_29.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 1\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp exhibit PL_Asahi_30.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 2\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp exhibit PL_Commerzbank_30.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 3\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp exhibit PL_MediaMarkt_30.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 4\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp_Exhibit_IT_Arkema_29.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 5\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp Exhibit_UK_Agilent_29.09.2025 checked.xlsx\n",
      "\n",
      "[PROCESSING] dcc based → Sample Folder: Sample 6\n",
      "[SAVED] Output written to: C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\\output_dcc\\Temp_Exhibit_AT_Sandoz_29.09.2025 checked.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from pandas.tseries.offsets import DateOffset, MonthEnd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "def calculate_lease_start(install_date, clause_type='monthly rule'):\n",
    "    if pd.isnull(install_date):\n",
    "        return None\n",
    "    # ✅ Do not change lease start date if installation is on the 1st\n",
    "    if install_date.day == 1:\n",
    "        return install_date\n",
    "\n",
    "    if clause_type == 'monthly rule':\n",
    "        return datetime(install_date.year + (install_date.month // 12),\n",
    "                        1 if install_date.month == 12 else install_date.month + 1,\n",
    "                        1)\n",
    "    elif clause_type == '2 weeks rule':\n",
    "        if install_date.day <= 15:\n",
    "            return datetime(install_date.year, install_date.month, 1)\n",
    "        else:\n",
    "            return datetime(install_date.year + (install_date.month // 12),\n",
    "                            1 if install_date.month == 12 else install_date.month + 1,\n",
    "                            1)\n",
    "            print(f\"Install date: {install_date} → Lease start: {lease_start}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_fis_data(fis_file_path):\n",
    "    header_df = pd.read_excel(fis_file_path, sheet_name=\"Header\", header=None)\n",
    "    billing_clause_value = None\n",
    "    for row in header_df.itertuples(index=False):\n",
    "        for col_idx, cell in enumerate(row):\n",
    "            if isinstance(cell, str) and \"billing start clause\" in cell.lower():\n",
    "                if col_idx + 1 < len(row):\n",
    "                    billing_clause_value = row[col_idx + 1]\n",
    "                break\n",
    "        if billing_clause_value is not None:\n",
    "            break\n",
    "\n",
    "    billing_clause_value = str(billing_clause_value).strip().lower()\n",
    "    if \"monthly\" in billing_clause_value:\n",
    "        billing_clause_value = \"monthly rule\"\n",
    "    elif \"2 week\" in billing_clause_value:\n",
    "        billing_clause_value = \"2 weeks rule\"\n",
    "    else:\n",
    "        billing_clause_value = \"monthly rule\"  # Default\n",
    "\n",
    "    fleet_df = pd.read_excel(fis_file_path, sheet_name=\"Fleet Data\", header=5)\n",
    "    fleet_df.columns = [str(col).strip() for col in fleet_df.columns]\n",
    "    serial_col = next((col for col in fleet_df.columns if \"serial\" in col.lower()), None)\n",
    "    \n",
    "    ms_map = fleet_df.set_index(serial_col)[\"MS Contract ID\"].to_dict() if \"MS Contract ID\" in fleet_df.columns else {}\n",
    "    co_map = fleet_df.set_index(serial_col)[\"CO_ID\"].to_dict() if \"CO_ID\" in fleet_df.columns else {}\n",
    "    \n",
    "    return billing_clause_value, ms_map, co_map\n",
    "\n",
    "def get_asset_data(asset_file_path):\n",
    "    preview = pd.read_excel(asset_file_path, sheet_name=0, nrows=10, header=None)\n",
    "    header_row = None\n",
    "    for i in range(len(preview)):\n",
    "        row = preview.iloc[i].astype(str).str.lower()\n",
    "        if row.str.contains(\"serial\").any() and row.str.contains(\"install\").any():\n",
    "            header_row = i\n",
    "            break\n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Header row not found in asset file\")\n",
    "\n",
    "    df = pd.read_excel(asset_file_path, header=header_row)\n",
    "    df.columns = [str(col).strip() for col in df.columns]\n",
    "\n",
    "    serial_col = next((col for col in df.columns if \"serial\" in col.lower()), None)\n",
    "    install_col = next((col for col in df.columns if \"install\" in col.lower()), None)\n",
    "    mfg_col = next((col for col in df.columns if \"routing\" in col.lower() or \"mfg pro\" in col.lower()), None)\n",
    "\n",
    "    df[install_col] = pd.to_datetime(df[install_col], errors='coerce')\n",
    "    install_map = df.set_index(serial_col)[install_col].to_dict()\n",
    "    mfg_map = df.set_index(serial_col)[mfg_col].to_dict() if mfg_col else {}\n",
    "\n",
    "    return install_map, mfg_map\n",
    "\n",
    "def read_clean_hardware_file(hw_path):\n",
    "    raw = pd.read_excel(hw_path, header=None, engine='openpyxl')\n",
    "    header_row = None\n",
    "    for i in range(min(30, len(raw))):\n",
    "        row = raw.iloc[i].astype(str).str.lower().fillna('')\n",
    "        if row.str.contains(\"product\").any() and row.str.contains(\"price\").any():\n",
    "            header_row = i\n",
    "            break\n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Header not found in hardware file\")\n",
    "    df = pd.read_excel(hw_path, header=header_row, engine='openpyxl')\n",
    "    df.columns = df.columns.map(lambda x: str(x).replace('\\n', ' ').strip())\n",
    "    return df, raw\n",
    "\n",
    "def calculate_lease_end(start_date_str, term_months):\n",
    "    if pd.isnull(start_date_str) or pd.isnull(term_months):\n",
    "        return \"\"\n",
    "    try:\n",
    "        start_date = pd.to_datetime(start_date_str, errors='coerce')\n",
    "        if pd.isnull(start_date):\n",
    "            return \"\"\n",
    "        end_date = start_date + DateOffset(months=int(term_months) - 1)\n",
    "        lease_end = end_date + MonthEnd(0)\n",
    "        return lease_end.strftime('%m/%d/%Y')\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_single_file(filtered_path, asset_path, hw_path, main_folder, base_type):\n",
    "\n",
    "    df = pd.read_excel(filtered_path)\n",
    "    df.columns = [str(col).strip() for col in df.columns]\n",
    "\n",
    "    lease_start_col = next((col for col in df.columns if str(col).lower().startswith(\"lease start date\")), None)\n",
    "    lease_end_col = next((col for col in df.columns if str(col).lower().startswith(\"lease end date\")), None)\n",
    "    if not lease_start_col:\n",
    "        print(f\"[SKIPPED] Lease start date column not found in {filtered_path}\")\n",
    "        return\n",
    "\n",
    "   # Check sheet names to determine file type\n",
    "    sheet_names = pd.ExcelFile(asset_path).sheet_names\n",
    "    \n",
    "    if \"Header\" in [s.strip().lower() for s in sheet_names] or \"Fleet Data\" in [s.strip().lower() for s in sheet_names]:\n",
    "        billing_clause, ms_map, co_map = get_fis_data(asset_path)\n",
    "    else:\n",
    "        billing_clause = \"monthly rule\"  # Default fallback\n",
    "        ms_map = {}\n",
    "        co_map = {}\n",
    "        \n",
    "    install_map, mfg_map = get_asset_data(asset_path)\n",
    "\n",
    "\n",
    "    df[lease_start_col] = df[\"SerialNumber\"].map(lambda sn: install_map.get(sn))\n",
    "    df[lease_start_col] = df[lease_start_col].apply(lambda d: calculate_lease_start(d, billing_clause))\n",
    "    df[lease_start_col] = pd.to_datetime(df[lease_start_col], errors='coerce')\n",
    "    df[lease_start_col] = df[lease_start_col].apply(lambda x: x.strftime('%m/%d/%Y') if pd.notnull(x) else \"\")\n",
    "\n",
    "    def get_serial_column(columns):\n",
    "        for option in [\"SerialNumber\", \"Serial_No\", \"serialnumber\", \"serial_no\"]:\n",
    "            if option in columns:\n",
    "                return option\n",
    "        raise ValueError(\"Serial number column not found\")\n",
    "\n",
    "    if \"fis\" in base_type.lower():\n",
    "        # Use raw FIS fleet dataframe again\n",
    "        fis_fleet_df = pd.read_excel(asset_path, sheet_name=\"Fleet Data\", header=5)\n",
    "        fis_fleet_df.columns = [str(col).strip() for col in fis_fleet_df.columns]\n",
    "    \n",
    "        try:\n",
    "            serial_col = get_serial_column(fis_fleet_df.columns)\n",
    "    \n",
    "            if \"MS Contract ID\" in fis_fleet_df.columns:\n",
    "                ms_contract_map = fis_fleet_df.set_index(serial_col)[\"MS Contract ID\"].to_dict()\n",
    "                df[\"MFG Pro#\"] = df[\"SerialNumber\"].map(ms_contract_map)\n",
    "            else:\n",
    "                print(f\"[WARNING] 'MS Contract ID' column not found in FIS file {asset_path}\")\n",
    "    \n",
    "            if \"CO_ID\" in fis_fleet_df.columns:\n",
    "                co_id_map = fis_fleet_df.set_index(serial_col)[\"CO_ID\"].to_dict()\n",
    "                df[\"Description\"] = df[\"SerialNumber\"].map(co_id_map)\n",
    "            else:\n",
    "                print(f\"[WARNING] 'CO_ID' column not found in FIS file {asset_path}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process FIS file: {e}\")\n",
    "    \n",
    "    elif \"dcc\" in base_type.lower():\n",
    "        if \"PurchaseOrderNo\" in df.columns:\n",
    "            def extract_description(po):\n",
    "                try:\n",
    "                    parts = str(po).split(\"_\")\n",
    "                    for i, part in enumerate(parts):\n",
    "                        if part == \"CO\" and i + 1 < len(parts):\n",
    "                            return f\"CO_{parts[i + 1]}\"\n",
    "                        elif part.startswith(\"CO_\"):\n",
    "                            return part\n",
    "                    return \"\"\n",
    "                except:\n",
    "                    return \"\"\n",
    "    \n",
    "            def extract_mfg_pro(po):\n",
    "                try:\n",
    "                    parts = str(po).split(\"_\")\n",
    "                    for part in parts:\n",
    "                        if len(part) == 8 and part.isalnum():\n",
    "                            return part.upper()\n",
    "                        # ✅ Case 2: 8-digit numeric (if ever occurs)\n",
    "                        elif len(part) == 8 and part.isdigit():\n",
    "                            return part\n",
    "                            \n",
    "                        # # ✅ Case 3: 10-character alphanumeric (if ever occurs)\n",
    "                        # elif len(part) == 10 and part.isalnum():\n",
    "                        #     return part.upper()\n",
    "                    return \"\"\n",
    "                except:\n",
    "                    return \"\"\n",
    "    \n",
    "            df[\"Description\"] = df[\"PurchaseOrderNo\"].apply(extract_description)\n",
    "            df[\"MFG Pro#\"] = df[\"PurchaseOrderNo\"].apply(extract_mfg_pro)\n",
    "        else:\n",
    "            df[\"MFG Pro#\"] = \"\"\n",
    "            df[\"Description\"] = \"\"\n",
    "            print(f\"[WARNING] 'PurchaseOrderNo' column not found in file: {filtered_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    hw_clean, hw_raw = read_clean_hardware_file(hw_path)\n",
    "\n",
    "    term = coterm = None\n",
    "    for row in hw_raw.itertuples(index=False):\n",
    "        for idx, cell in enumerate(row):\n",
    "            if isinstance(cell, str):\n",
    "                if \"pricing term\" in cell.lower() and term is None:\n",
    "                    term = row[idx + 1] if idx + 1 < len(row) else \"\"\n",
    "                if \"coterminous\" in cell.lower() and coterm is None:\n",
    "                    coterm = row[idx + 1] if idx + 1 < len(row) else \"\"\n",
    "    df[\"Term\"] = term\n",
    "    df[\"Coterminous Y/N?\"] = coterm if coterm else \"\"\n",
    "\n",
    "    if lease_start_col and \"Term\" in df.columns:\n",
    "        df[lease_end_col if lease_end_col else \"Lease end date(mm/dd/yyyy)\"] = df.apply(\n",
    "            lambda row: calculate_lease_end(row[lease_start_col], row[\"Term\"]),\n",
    "            axis=1\n",
    "        )\n",
    "    if \"ProductNumber\" in df.columns and \"NetUnitPrice\" in df.columns:\n",
    "        # Keep original ProductNumber in df\n",
    "        df[\"_CleanProductNumber\"] = (\n",
    "            df[\"ProductNumber\"].astype(str).str.split(\"#\").str[0].str.strip().str.upper()\n",
    "        )\n",
    "    \n",
    "        hw_clean[\"Product Number\"] = (\n",
    "            hw_clean.get(\"Product Number\", \"\").astype(str).str.split(\"#\").str[0].str.strip().str.upper()\n",
    "        )\n",
    "        hw_clean[\"Logistics Part Nbr\"] = (\n",
    "            hw_clean.get(\"Logistics Part Nbr\", \"\").astype(str).str.split(\"#\").str[0].str.strip().str.upper()\n",
    "        )\n",
    "\n",
    "        \n",
    "    \n",
    "        # Build a mapping from product to all possible prices\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        product_price_map = defaultdict(list)\n",
    "        \n",
    "        if \"OPG / BD Net Price\" in hw_clean.columns:\n",
    "            hw_clean[\"OPG / BD Net Price\"] = pd.to_numeric(hw_clean[\"OPG / BD Net Price\"], errors='coerce')\n",
    "            hw_clean[\"Copyright Fee\"] = pd.to_numeric(hw_clean.get(\"Copyright Fee\", 0), errors='coerce').fillna(0)\n",
    "            hw_clean[\"calculated_price\"] = hw_clean[\"OPG / BD Net Price\"] + hw_clean[\"Copyright Fee\"]\n",
    "            for prod, price in hw_clean.set_index(\"Product Number\")[\"calculated_price\"].dropna().items():\n",
    "                product_price_map[prod].append(price)\n",
    "        \n",
    "        if \"Price\" in hw_clean.columns:\n",
    "            hw_clean[\"Price\"] = pd.to_numeric(hw_clean[\"Price\"], errors='coerce')\n",
    "            for prod, price in hw_clean.set_index(\"Logistics Part Nbr\")[\"Price\"].dropna().items():\n",
    "                product_price_map[prod].append(price)\n",
    "        \n",
    "        # Updated price match function\n",
    "        def price_match_logic(row):\n",
    "            product = row[\"_CleanProductNumber\"]\n",
    "            net_price = row[\"NetUnitPrice\"]\n",
    "            \n",
    "            if pd.isnull(net_price):\n",
    "                return \"\"\n",
    "            \n",
    "            possible_prices = product_price_map.get(product, [])\n",
    "            \n",
    "            # Print all available prices for debug\n",
    "            # print(f\"Product: {product}, NetUnitPrice: {net_price}, Hardware Prices: {possible_prices}\")\n",
    "            \n",
    "            if not possible_prices:\n",
    "                return \"Product Number not found\"\n",
    "            \n",
    "            # Check if any hardware price matches exactly\n",
    "            for price in possible_prices:\n",
    "                if abs(net_price - price) < 0.01:  # exact match within rounding tolerance\n",
    "                    return \"Match\"\n",
    "            \n",
    "            return \"Mismatch\"\n",
    "        \n",
    "        # Apply to dataframe\n",
    "        df[\"Price Match\"] = df.apply(price_match_logic, axis=1)\n",
    "\n",
    "  \n",
    "        # Variance logic with \"check next row if missing\"\n",
    "        # Collect lease price + LRF per row (not separately)\n",
    "        lease_lrf_map = defaultdict(list)\n",
    "        \n",
    "        if \"Leasing Net Price\" in hw_clean.columns and \"LRF\" in hw_clean.columns:\n",
    "            hw_clean[\"Leasing Net Price\"] = pd.to_numeric(hw_clean[\"Leasing Net Price\"], errors=\"coerce\")\n",
    "            hw_clean[\"LRF\"] = pd.to_numeric(hw_clean[\"LRF\"].ffill(), errors=\"coerce\")  # forward fill\n",
    "        \n",
    "            for _, row in hw_clean.iterrows():\n",
    "                lease_price = row.get(\"Leasing Net Price\")\n",
    "                lrf = row.get(\"LRF\")\n",
    "                prod1 = str(row.get(\"Product Number\", \"\")).split(\"#\")[0].strip().upper()\n",
    "                prod2 = str(row.get(\"Logistics Part Nbr\", \"\")).split(\"#\")[0].strip().upper()\n",
    "        \n",
    "                if pd.notna(lease_price) and pd.notna(lrf) and lease_price != 0:\n",
    "                    if prod1:\n",
    "                        lease_lrf_map[prod1].append((lease_price, lrf))\n",
    "                    if prod2:\n",
    "                        lease_lrf_map[prod2].append((lease_price, lrf))\n",
    "\n",
    "        \n",
    "        def compute_variance(row):\n",
    "            prod = row[\"_CleanProductNumber\"]\n",
    "            serial = row.get(\"SerialNumber\", \"\")\n",
    "            quantity = row.get(\"OrderedQuantity\", 1)\n",
    "        \n",
    "            try:\n",
    "                quantity = int(quantity)\n",
    "            except:\n",
    "                quantity = 1\n",
    "        \n",
    "            pairs = lease_lrf_map.get(prod, [])\n",
    "        \n",
    "            # Debug print\n",
    "            #print(f\"[DEBUG Variance] Product: {prod}, Serial: {serial}, Qty: {quantity}, Pairs: {pairs}\")\n",
    "        \n",
    "            if not pairs or prod in {\"ZD052A\", \"ZD053A\", \"ZD054A\"}:\n",
    "                return \"\"\n",
    "        \n",
    "            # Take the first available pair (you could also loop through if multiple exist)\n",
    "            lease_price, lrf = pairs[0]\n",
    "        \n",
    "            if pd.isna(serial) or str(serial).strip() == \"\":\n",
    "                return round(lease_price * lrf * quantity, 2)\n",
    "            else:\n",
    "                return round(lease_price * lrf, 2)\n",
    "\n",
    "        df[\"Variance Amount\"] = df.apply(compute_variance, axis=1)\n",
    "        \n",
    "        # Drop temp column before saving\n",
    "        df.drop(columns=[\"_CleanProductNumber\"], inplace=True)\n",
    "\n",
    "        # Output folder logic\n",
    "            # Output folder logic\n",
    "        base_type_clean = base_type.replace(\" \", \"_\").lower()  # \"fis based\" → \"fis_based\"\n",
    "        output_folder_name = \"output_fis\" if \"fis\" in base_type_clean else \"output_dcc\"\n",
    "        output_folder = os.path.join(main_folder, output_folder_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "        file_name = os.path.basename(filtered_path)\n",
    "        out_path = os.path.join(output_folder, file_name.replace(\".xlsx\", \" checked.xlsx\").replace(\".xlsm\", \" checked.xlsm\"))\n",
    "    \n",
    "        df.to_excel(out_path, index=False)\n",
    "        print(f\"[SAVED] Output written to: {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_all_subfolders(main_folder):\n",
    "    # Normalize folder names (case-insensitive match)\n",
    "    all_base_folders = {folder.lower(): os.path.join(main_folder, folder)\n",
    "                        for folder in os.listdir(main_folder)\n",
    "                        if os.path.isdir(os.path.join(main_folder, folder))}\n",
    "\n",
    "    base_folders = {\n",
    "        \"fis based\": all_base_folders.get(\"fis based\"),\n",
    "        \"dcc based\": all_base_folders.get(\"dcc based\")\n",
    "    }\n",
    "\n",
    "    for base_type, base_path in base_folders.items():\n",
    "        if not base_path:\n",
    "            print(f\"[SKIPPED] '{base_type}' folder not found in main folder.\")\n",
    "            continue\n",
    "\n",
    "        for subfolder in os.listdir(base_path):\n",
    "            subfolder_path = os.path.join(base_path, subfolder)\n",
    "            if not os.path.isdir(subfolder_path):\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n[PROCESSING] {base_type} → Sample Folder: {subfolder}\")\n",
    "            filtered_file = None\n",
    "            hardware_file = None\n",
    "            asset_or_fis_file = None\n",
    "\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                file_lower = file.lower()\n",
    "            \n",
    "                if any(x in file_lower for x in [\"temp exhibit\", \"temp_exhibit\"]) and file_lower.endswith(('.xlsx', '.xlsm')):\n",
    "                    filtered_file = os.path.join(subfolder_path, file)\n",
    "            \n",
    "                elif \"supplychainoutput-hardware\" in file_lower and file_lower.endswith(('.xlsx', '.xlsm')):\n",
    "                    hardware_file = os.path.join(subfolder_path, file)\n",
    "            \n",
    "                elif file_lower.endswith(('.xlsx', '.xlsm')):\n",
    "                    if base_type == \"fis based\" and \"fis\" in file_lower:\n",
    "                        asset_or_fis_file = os.path.join(subfolder_path, file)\n",
    "                    elif base_type == \"dcc based\" and \"asset\" in file_lower:\n",
    "                        asset_or_fis_file = os.path.join(subfolder_path, file)\n",
    "\n",
    "\n",
    "            if not (filtered_file and hardware_file and asset_or_fis_file):\n",
    "                print(f\"[SKIPPED] Missing one or more required files in: {subfolder_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                process_single_file(\n",
    "                    filtered_file,\n",
    "                    asset_or_fis_file,\n",
    "                    hardware_file,\n",
    "                    main_folder,\n",
    "                    base_type\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed processing {filtered_file}: {e}\")\n",
    "\n",
    "# Update this path as needed\n",
    "\n",
    "main_folder = r\"C:\\Users\\AtCh030\\Desktop\\COI-COA Bot Input\\September testing_2nd round\\September testing_2nd round\"\n",
    "process_all_subfolders(main_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6991a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
